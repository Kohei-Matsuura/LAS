# LAS

## はじめに
このリポジトリは，研究で使用している音声認識システムを限定して共有するためのものです。  
<!-- 勝手にKaldiのyesno音声データ('data/toy')を載せている事実などが主にヤバいので，一般公開は想定されていません。 -->


## 音声認識モデルについて
このモデルは[S. Ueno et al. ICASSP, 2018](http://www.sap.ist.i.kyoto-u.ac.jp/lab/bib/intl/UEN-ICASSP18.pdf)に基づいて再実装されたものです。  
<!--
## ライセンスのようなもの
このリポジトリにアクセスできる人は基本的に自由に使ってもらって構いません。  
その他の人に渡したい場合は相談してください。
-->

## できること
音響特徴量（対数メル尺度フィルタバンクを採用しています。具体的には後述）からテキスト列を推定します。  
綺麗にアノテーションされた300時間のデータがあれば，だいたい90%くらい正解します。

## 必要なもの
Python >= 3.6.0  
PyTorch >= 1.0

GPUを使用するにあたって，以下が必要です。  
CUDA >= 9.0

## 動作環境
本モデルは Ubuntu 16.04 下で開発されました。  
その他の環境でどうなるかは試したことが無いので不明です…

## 動作の確認
LASディレクトリで次を実行してください。

```
./toy_scripts/toy.test.bat
```

toyデータによる動作確認ができます。音声は，男性が'yes'か'no'を8回発言するものが60個あります。  
（'data/toy/waves'にあります。ファイル名が内容を表しており，'0'が'no'，'1'が'yes'です。）    
このうち57個でモデルの学習を行い，3個でテストします。  
GPUを使用する場合，30分程度待つとテストの結果が出てきます。  

## 使い方
### モデルの学習
次のステップに従ってください。

0. 仮定
- 細切れの音声と，それに対応するラベルが存在すると仮定します。  
この時，音声長はバラバラで大丈夫ですが，最大でも15秒までをお勧めします。

- もし音声が一つの大きなファイルの場合，これを無音区間で適当に区切る必要があります。  
大抵の場合，この分割の通りにテキストを分割するのが最もお金のかかる箇所です。

1. 音声（wav形式）を全て音響特徴量に変換します。
- [HTKツールキット](http://htk.eng.cam.ac.uk/)のHCopyコマンドを用います。  
コマンドには「どのように変換するか」の設定ファイルが必要ですが，私は次のように設定しています。  
    ```config
    # coding parameters
    SOURCEFORMAT = WAV
    TARGETKIND = FBANK_D_A
    #DELTAWINDOW = 2
    #ACCWINDOW = 2
    TARGETRATE = 100000.0
    SAVECOMPRESSED = F
    SAVEWITHCRC = F
    WINDOWSIZE = 250000.0
    USEHAMMING = T
    PREEMCOEF = 0.97
    NUMCHANS = 40
    ENORMALISE = F
    ```  
- 変換したデータの拡張子は何でも良いですが，こだわりが無ければ.htkとしてください。  
- その後，平均0，分散1に全データを正規化すると学習が比較的うまくいきます。
  
2. テキストと対応付けたファイルを作成してください。  
- \<sos>，\<eos>はそれぞれ文の始まりと終わりを表す特殊記号です  
- スペースは全て半角で。
    ```sample.list
    XXX.htk <sos> 今日 は 良く 寝 た のに <eos>
    XXX.htk <sos> 全く 疲れ が 取れ ない な <eos>
    ```

3. テキストをIDに変換してください。
- 次のような感じです。便宜上これを「スクリプト」と呼びます。  
XXX.htkは音響特徴量が保存されているディレクトリです。
    ```sample.script
    XXX.htk 0 1203 7134 405 493 221 193 1
    XXX.htk 0 5508 3302 1205 985 8746 56 1
    ```
- 音声の短い順に
- このとき，次のような対応リストもできると思います。  
デコード時に必要なので保持しておいてください。
    ```sample.id
    <sos> 0
    <eos> 1
    …
    今日 1203
    …
    ```

4. スクリプトを次のようにモデルに与えてしばらく待ちます。  
学習はいつか終わります。日本語ならだいたい数十時間のオーダーです。
    ```
    ./train.bat <modelの保存先> <スクリプトの場所> <単語の種類数>
    ```
- 何番のGPUを使用するか否かはtrain.batとeval.bat内でそれぞれ変更できます。  
使用できるGPUが無い場合勝手にCPUで学習を始めます。遅いですが動作確認は可能です。

5. その他
- systems/hparams.pyの中でハイパーパラメータなどを指定できます。  
重要なのは次の3つだと思います。  
    - \<sos>などのidの指定  
    - データを何周学習するか（EPOCH_NUM）  
    - 一度にいくつの音声を入力するか（BATCH_SIZE）

### テキストの推定
1. 変換したい音響特徴量について，次のようなスクリプトを作成してください。  
学習スクリプトのテキストが無いバージョンです。
    ```sample.script
    XXX.htk
    XXX.htk
    ```

2. 次のようにeval.batを実行します。
    ```
    ./eval.bat <使用したいmodelの場所> <1.のスクリプトの場所> <単語の種類数>
    ```
